/section{Grundlagen}
2.1	Allgemeine Definitionen
Authentifizierung bezeichnet den technischen Prozess, bei dem ein System die behauptete, digitale Identität einer Person prüft. Dabei ist sie von Identitätsfeststellung (Identity Proofing) und Autorisierung zu unterscheiden (Temoshok et al., 2025a–c).
Klassisch erfolgte Authentifizierung mittels eines Faktors, über Wissen (zum Beispiel Passwort). Angesichts bekannter Schwächen von Passwörtern und darauf abgestimmter Angriffsformen empfiehlt der NIST-Rahmen abhängig vom Risiko der Anwendung höhere Authenticator Assurance Levels (AAL) bis hin zu verpflichtender Multifaktor-Authentifizierung (MFA) (Temoshok, 2025; Temoshok et al., 2025b).
MFA kombiniert mindestens zwei unabhängige Faktorarten (Lawrence O’Gorman & O’Gorman, 2003, S. 2022):
•	Besitz („Something you have“): Smartcard, Hardware-Schlüssel, Token .
•	Inhärenz („Something you are“): biometrische Merkmale (zum Beispiel Fingerabdruck, Gesichtsscan).
•	Wissen („Something you know“): Passwort, PIN, Sicherheitsfragen.
Neue Darstellungen erweitern diese drei klassischen Faktoren um zwei weitere: 
•	Ortsbezug (“Somewhere you are”): IP-Adresse, Geolocation
•	Tätigkeitsbezug („Something you do“): Verhalten mit dem Gerät, Klick- und Tippverhalten (Multifactor Authentication - OWASP Cheat Sheet Series, o. J.).
Für den vorliegenden Text liegt der Fokus jedoch auf den obengenannten Faktoren. Einerseits aufgrund ihrer dichteren Forschungslage, andererseits um Kreuzbeziehungen (zum Beispiel: Wie wirkt Unternehmensgovernance auf den Arbeitsort und die IP-Adresse bei Home-Office-Regelungen) zu reduzieren, die hier nicht in der gebührenden Komplexität dargestellt werden könnten.
Zur Absicherung digitaler Identitäten wird eine Kombination mehrere etablierter Protokolle und Technologien verwendet um, sowohl die Identitätsprüfung als auch die Zugriffssteuerung zu regeln (Rose et al., 2020, S. 6). Auf diese wird in Folge genauer eingegangen.
Während traditionelle Modelle oft auf örtlichen (sogenannten perimeterbasierten) Ansätzen beruhten, erfordern moderne Architekturen eine kleinteilige Unterscheidung zwischen der Verifizierung einer Identität (Authentifizierung) und der Gewährung von Zugriffsrechten (Autorisierung) (Shirey, 2007, S. 25–28).
Entscheidend ist die Unabhängigkeit der Faktoren voneinander, aber auch ihre Bindung an die Nutzer:in und das verwendete Protokoll (zum Beispiel bei einem kryptografischen Herausforderungs-Antwort-Verfahren). Damit steigt die Resistenz gegen Phishing, oder technische Manipulation FIDO2/WebAuthn als besitzbasierten, kryptografischen Faktoren (Juan Lang et al., 2016, S. 423).
In risikobasierten Ansätzen (RBA) werden zusätzliche Faktoren bei auffälligem Kontext angefordert (Stephan Wiefling et al., 2019). Allerdings sind sie, in Hinblick auf die Anfälligkeit von Passwörtern, durchaus auch unter anderen Umständen zu empfehlen (Otta et al., 2023, S. 4). 
2.2	Historische Entwicklung – von 1FA zu MFA
“In times gone by, authentication was not a complex task. One person, call her Alice, would meet another person, Bob, and either recognize him by visual appearance or not. […] Now we cannot “see” the entity on the remote end of a computer network, and indeed the entity could be a friend, a machine, or an attacker. We exchange personal information, such as financial and health data, that we wish to remain as private and as confidential as correspondence between spies.” (O’Gorman, 2003, S. 2001)
Die Entwicklung der digitalen Authentifizierung ist eng mit der allgemeinen Informationssicherheit verbunden. Schon in den 1960er-Jahren wurden Passwörter als primäre Methode zur Zugangskontrolle eingeführt und über Jahrzehnte als Standard eingesetzt (Joseph Bonneau et al., 2015, S. 78–80). Dieses Prinzip geht von der Annahme aus, dass nur autorisierte Personen das zugrunde liegende „Geheimnis“ kennen (Lawrence O’Gorman & O’Gorman, 2003, S. 2022).
Mit der zunehmenden Vernetzung und Komplexität moderner IT-Systeme steigen allerdings die Sicherheitsrisiken sukzessiv. Das beeinflusst nur teilweise die Sensibilisierung von Nutezr:innen bezüglich IT-Risiken: Empirische Studien zeigen, dass Nutzer:Innen häufig dieselben oder sehr einfache Passwörter für mehrere Dienste wiederverwenden, um die kognitive Belastung zu reduzieren (Dinei Florêncio et al., 2007, S. 660). Diese Menschlichkeit führt zu einer hohen Anfälligkeit für Angriffe wie Credential Stuffing (Kunke et al., 2021, S. 59) und erleichtert Brute-Force-Angriffe (Joseph Bonneau et al., 2012, S. 555).
Als Reaktion auf diese Schwachstelle entstanden Zwei-Faktor-Authentifizierungsverfahren (2FA), die erstmals Besitzfaktoren wie Hardware-Token oder mobile TAN-Generatoren einbezogen. Der Übergang zur Mehrfaktor-Authentifizierung (MFA) erfolgte evolutionär, indem biometrische und kontextbezogene Merkmale ergänzt wurden (NIST SP 800-63B, Temoshok, 2025, S. 14.
Aktuelle Authentifizierungssysteme vereinen technische Innovationen mit Anforderungen an Datenschutz, Benutzerfreundlichkeit und regulatorische Vorgaben, etwa im Finanzwesen durch die Zahlungsdienst-Richtlinie PSD2 (de Bruijn & Janssen, 2017, S. 3). Damit bildet MFA heute einen zentralen Bestandteil moderner Sicherheitsarchitekturen, der technologische sowie auch organisatorische Aspekte vereint.
Aktuelle Multi-Faktor-Authentifizierungssysteme (MFA) nutzen eine Vielzahl technischer Verfahren, die sich (unter anderem) im Sicherheitsniveau, hinsichtlich ihrer Benutzerfreundlichkeit und im Implementierungsaufwand unterscheiden (Mohammed et al., 2023, S. 4).
Die Verbindung mehrerer Faktoren erhöht die Resilienz gegenüber unbefugten Zugriffen, da Angreifer:innen nicht mehr nur ein einzelnes Geheimnis kompromittieren müssen. Dabei ist die erwähnte Unabhängigkeit der Faktoren und Bindung der Faktoren an Gerät und Nutzer:in entscheidend, wie sie in den Digital Identity Guidelines des NIST definiert sind (Temoshok et al., 2025, S. 12–14). Zu diesem Zweck werden im Folgenden relevante Technologien und Protokolle kurz vorgestellt.
2.3	Relevante Protokolle und Technologien
2.3.1	Authentifizierung & Autorisierung
Die Authentifizierung ist der Prozess, bei dem ein Anspruchsteller (Claimant) den Besitz und die Kontrolle über einen oder mehrere Authentifikatoren nachweist, um seine Identität gegenüber einem Bestätiger (Verifier) zu bestätigen (Temoshok et al., 2025, S. 4–5). Authentifizierungsmethoden basieren traditionell, wie einleitend erwähnt, auf drei Faktoren (NIST SP 800-63 Digital Identity Guidelines, o. J.).
Da simple Passwörter anfällig für Diebstahl und Phishing sind, gilt die MFA als Standard für höhere Sicherheitsanforderungen. MFA kombiniert mindestens zwei verschiedene dieser Faktoren, um die Sicherheit über die bloße Kenntnis eines Geheimnisses hinaus zu erhöhen; also zu Authentifizieren (Ometov et al., 2018, S. 3).
Einmalpasswörter (one-time password, OTP) beruhen auf kurzlebigen Codes, die entweder zeit- (time-based one-time password TOTP) oder zählerbasiert (HMAC-basiert HOTP) generiert werden (M’Raihi et al., 2011, S. 3-4).
Wird der Code per App oder Hardware-Token erzeugt, gilt das Verfahren als relativ sicher (O’Gorman, 2003). SMS-basierte Übermittlungen sind hingegen anfällig für Phishing und SIM-Swapping-Angriffe (Enis Ulqinaku et al., 2020, S. 1200–1201).
Hardware-Token und Smartcards stellen physische Besitzfaktoren dar, die über kryptografische Verfahren (beispielsweise U2F, FIDO2) eine Challenge-Response-Authentifizierung ermöglichen. Diese Lösungen gelten als besonders resistent gegen Phishing und Replay-Angriffe (Lang et al., 2016, S. 424–427), erfordern jedoch organisatorischen Aufwand bei Verwaltung und Einsatz (Katharina Pfeffer et al., 2021, S. 40–42).
Biometrische Authentifizierung nutzt inhärente Merkmale wie Fingerabdruck, Gesicht oder Stimme. Sie bietet leichte Nutzung, wirft aber Fragen zum Datenschutz, zur Einwilligung und zu möglichen Spoofing-Risiken auf (Trewin et al., 2012, S. 160–163; Wolf et al., 2019, S. 151).
Ein zentraler Standard für Authentifizierung ist FIDO2, der vom W3C und der FIDO-Alliance entwickelt wurde. Er besteht aus der Web Authentication API (WebAuthn) und dem Client-to-Authenticator-Protocol (CTAP). FIDO2 ermöglicht passwortlose Authentifizierung durch asymmetrische Kryptographie, bei der private Schlüssel sicher auf einem Authentifikator (zum Beispiel YubiKey oder Smartphone-TPM) gespeichert werden und den Servern nur der öffentliche Schlüssel bekannt ist (Sanam Ghorbani Lyastani et al., 2020, S. 269).
Zur Klassifizierung der Stärke von Authentifizierungsprozessen definiert das NIST Authentication Assurance Levels (AAL). AAL1 erfordert einfache Authentifizierung, AAL2 verlangt MFA mit zwei Faktoren, und AAL3 setzt den Einsatz kryptografischer Hardware-Token voraus, die resistent gegen Verifier-Impersonation (Phishing) sind (Temoshok et al., 2025, S. 13–14).
Nach einer erfolgreichen Authentifizierung regelt die Autorisierung, auf welche Ressourcen zugeriffen werden kann, also, welcher Account auf welche Art autorisiert ist. In modernen IT-Architekturen erfolgt dies oft dynamisch und kontextbezogen (Rose et al., 2020, S. 6).
Häufig genutzte Modelle sind Role-Based Access Control (RBAC), bei welchem Rechte an Rollen gebunden sind, sowie Attribute-Based Access Control (ABAC), das Entscheidungen basierend auf Attributen der Nutzenden und der Umgebung trifft (Hu et al., 2014, S. 4).
Im Rahmen von Zero Trust und modernen Sicherheits-Frameworks wird das Prinzip der minimalen Rechtevergabe (Least Privilege Access) durchgesetzt. Dies kann durch Just-In-Time (JIT) Zugriff erweitert werden, bei dem Privilegien nur temporär für einen spezifischen Zeitraum oder eine Aufgabe gewährt werden (Rose et al., 2020, S. 12).
In zentral verwalteten Umgebungen (zum Beispiel Single Sign-On in einem Unternehmen) überträgt ein Identity Provider (IdP) Autorisierungsinformationen mittels Assertions (zum Beispiel via SAML oder OIDC) an den Relying Party (RP). Das NIST definiert hierfür Federation Assurance Levels (FAL), die festlegen, wie stark die Assertion gegen Manipulation und Injektionsangriffe geschützt ist (Temoshok et al., 2025, S. 40–44).
2.3.2	Endgeräte
Die Sicherheit des Endgeräts spielt eine entscheidende Rolle bei der Autorisierungsentscheidung, da selbst eine valide Benutzeridentität auf einem kompromittierten Gerät ein Risiko darstellt.
Technologien zur Autorisierung unterscheiden zwischen Plattform Authenticators (im Endgerät integriert, zum Beispiel Apple Touch ID, Windows Hello), die oft biometrische Faktoren nutzen, und Roaming Authenticators (zum Beispiel YubiKeys), die zwischen Geräten gewechselt werden können. Die Nutzung integrierter Plattform-Authentifikatoren bindet den Zugriff stark an das spezifische Endgerät.
Authenticator-Apps wie Google Authenticator oder Microsoft Authenticator implementieren typischerweise das TOTP-Verfahren (wie definiert in RFC 6238 (M’Raihi et al., 2011)). Sie sind von Mobilfunknetzen unabhängig und bieten dadurch ein höheres Sicherheitsniveau bei geringem Bedienaufwand (Temoshok et al., 2025, § 4, S. 13).
In einer Zero-Trust-Architektur wird keinem Gerät implizit vertraut (Rose et al., 2020, S. 11). Der Sicherheitsstatus (Device Posture), zum Beispiel Patch-Level, Malware-Freiheit oder Standort, wird kontinuierlich überwacht und fließt in Echtzeit in die Autorisierungsentscheidung ein.
Um automatisierte Angriffe zu verhindern, werden Techniken wie Device Fingerprinting eingesetzt, um ein Gerät eindeutig zu identifizieren und an einen Benutzeraccount zu binden. Dies verhindert, dass gestohlene Zugangsdaten (wie Session-Cookies) auf fremden Geräten genutzt werden können, und ermöglicht eine präzisere Risikobewertung.
Die Einbindung privater Endgeräte (Bring Your Own Device) stellt besondere Anforderungen an die Autorisierung, da hier die Balance zwischen Sicherheitskontrolle durch die Organisation und der Privatsphäre des Nutzers gewahrt werden muss.
Die Verbindung mehrerer Faktoren erhöht die Resilienz gegenüber unbefugten Zugriffen, da Angreifer:innen nicht mehr nur ein einzelnes Geheimnis kompromittieren müssen. Dabei ist die erwähnte Unabhängigkeit der Faktoren und Bindung der Faktoren an Gerät und Nutzer:in entscheidend, wie sie in den Digital Identity Guidelines des NIST definiert sind (Temoshok et al., 2025, S. 12–14). Zu diesem Zweck werden im Folgenden relevante Technologien und Protokolle kurz vorgestellt.
Als letztes soll auch die Kategorie Passwordless vorgestellt werden: Passwordlose Verfahren  (Passwordless Login) ersetzen den Faktor „Wissen“, also ein Passwort, durch Public-Key-Kryptografie und biometrische Verifikation. Moderne Standards wie FIDO2 oder Passkeys gelten als phishing-resistent und benutzerfreundlich, werden jedoch in der Praxis  eher zögerlich implementiert (Lyastani et al., 2020, S. 270).
2.4	MFA und Regulatorik
Die Implementierung von Multifaktor-Authentifizierung ist in der modernen IT-Governance nicht mehr rein risikobasiert, sondern wird zunehmend durch regulatorische Vorgaben der Europäischen Union mandatiert. Insbesondere drei Rahmenwerke sind hierbei von zentraler Bedeutung: die NIS-2-Richtlinie, DORA und die DSGVO.
Die NIS- beziehungsweise NIS2-Richtlinie (Network and Information Security Directive) erweitert den Kreis der betroffenen Unternehmen („Essential“ und „Important Entities“) und verschärft die Anforderungen an die Cybersicherheit. Da sich das Inkraftteten der NIS-2 in Österreich noch verzögert wird hier stattdessen die Lex Spazialis des Digital Operational Resilience Act (DORA) herangezogen. DORA zielt auf die digitale Widerstandsfähigkeit von Finanzunternehmen ab und schreibt strenge Anforderungen an (unter anderem) das IKT-Risikomanagement vor. Bezogen auf das Identitätsmanagements verlangt DORA robuste Authentifizierungsmechanismen, um den Zugriff auf IKT-Systeme und Daten zu schützen, wobei MFA als Standardmaßnahme gilt, um die Integrität von Finanztransaktionen und Kundendaten zu gewährleisten.
Auch die Datenschutz-Grundverordnung (kurz: DSGVO) wirkt als indirekter Treiber. Zwar nennt sie MFA nicht explizit, jedoch fordert Artikel 32 „geeignete technische und organisatorische Maßnahmen“,  um ein dem Risiko angemessenes Schutzniveau zu gewährleisten. Aufsichtsbehörden und die ENISA interpretieren MFA heute als „Stand der Technik“ für den Zugriff auf sensible personenbezogene Daten, womit eine Nicht-Verwendung bei einem Data Breach als Verstoß gegen die DSGVO gewertet werden kann.
2.5	Verwendungskontext und Akzeptanz
Die Nutzung von MFA unterscheidet sich deutlich zwischen privaten und beruflichen Kontexten. Im privaten Bereich ist MFA häufig optional und wird vor allem dort schlagend, wo regulatorische Vorgaben bestehen – zum Beispiel im Online-Banking durch PSD2 (Govindraj C.V., 2024, S. 2). Dabei stehen persönliche Faktoren, wie Bequemlichkeit und Datenschutzbedenken im Vordergrund.
Im beruflichen Umfeld ist IT-Governance ein treibender Faktor für die Akzeptanz von MFA. Da Sicherheit oft nicht im Fokus der Nutzer:innen ist, erzwingt Governance die Nutzung, beispielsweise durch Richtlinien und technische Kontrollen (Das et al., 2020, S. 5). 
In solchen Frameworks ist MFA meist verpflichtender Bestandteil eines Identity and Access Management (IAM) und dient der Einhaltung von Sicherheits,- und Compliance-Standards (ISO 27001, NIST AAL2–3). Dabei erfordert ein Kompromiss zwischen Sicherheit und Benutzerfreundlichkeit sorgfältiges Vorgehen (Marky et al., 2022, ).
Zentrale Erfolgsfaktoren für die Akzeptanz von MFA-Systemen sind daher: Onboarding (Das et al., 2018, S. 6), risikobasierte Adaption der Systeme, Datenschutz und Fallback-Möglichkeiten. 
Erstens intuitives Onboarding, denn eine verständliche Ersteinrichtung steigert die Akzeptanz gegenüber der Technologie (Jessica Colnago et al., 2018, S. 458–460). Zweitens minimiert die risikobasierte Authentifizierung zusätzlich Reibung, indem weitere Faktoren nur bei Bedarf, wie etwa verdächtigen Anmeldeversuchen, verlangt werden (Stephan Wiefling et al., 2019, S. 140). Drittens: Sichere Wiederherstellungsmechanismen – zum Beispiel Backup-Codes oder Hardware-Ersatz – sind notwendig, dürfen aber keine neuen Angriffsvektoren eröffnen (Klivan et al., 2023, S. 3140; Keil & Zugenmaier, 2024). Und zuletzt: Datenschutzkonformität: Biometrische und kontextbasierte Verfahren müssen der DSGVO entsprechen (Zweckbindung, Einwilligung, Datensparsamkeit). Die Wahrnehmung von Privatsphäre beeinflusst die Akzeptanz erheblich (Naresh K. Malhotra et al., 2004, S. 340–341) Dienlin und Trepte, 2015, S. 285).
Eine strategische Einführung der Technologie mit Schulungen, klaren Kommunikationsmaßnahmen und definierten Recovery-Prozessen sind bei Cybersecurity und Governance generell für den Erfolg entscheidend (Hans de Bruijn et al., 2017, S. 4).
